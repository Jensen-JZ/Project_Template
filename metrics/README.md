# Metrics

This directory is a placeholder for user-defined metric calculations.
You can add scripts or modules here to compute metrics relevant to your specific models and tasks.

For example, you might include:
- Accuracy, Precision, Recall, F1-score for classification tasks.
- Mean Squared Error (MSE), Mean Absolute Error (MAE) for regression tasks.
- Custom evaluation scripts for your specific domain.

Refer to the main `solver.py` or create helper functions here to integrate these metrics into your training and evaluation loops.
